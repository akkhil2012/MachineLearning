{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X ~ n_samples x n_features: (1797, 64)\n",
      "y ~ n_samples: (1797,)\n",
      "\n",
      "First 5 samples:\n",
      " [[  0.   0.   5.  13.   9.   1.   0.   0.   0.   0.  13.  15.  10.  15.\n",
      "    5.   0.   0.   3.  15.   2.   0.  11.   8.   0.   0.   4.  12.   0.\n",
      "    0.   8.   8.   0.   0.   5.   8.   0.   0.   9.   8.   0.   0.   4.\n",
      "   11.   0.   1.  12.   7.   0.   0.   2.  14.   5.  10.  12.   0.   0.\n",
      "    0.   0.   6.  13.  10.   0.   0.   0.]\n",
      " [  0.   0.   0.  12.  13.   5.   0.   0.   0.   0.   0.  11.  16.   9.\n",
      "    0.   0.   0.   0.   3.  15.  16.   6.   0.   0.   0.   7.  15.  16.\n",
      "   16.   2.   0.   0.   0.   0.   1.  16.  16.   3.   0.   0.   0.   0.\n",
      "    1.  16.  16.   6.   0.   0.   0.   0.   1.  16.  16.   6.   0.   0.\n",
      "    0.   0.   0.  11.  16.  10.   0.   0.]\n",
      " [  0.   0.   0.   4.  15.  12.   0.   0.   0.   0.   3.  16.  15.  14.\n",
      "    0.   0.   0.   0.   8.  13.   8.  16.   0.   0.   0.   0.   1.   6.\n",
      "   15.  11.   0.   0.   0.   1.   8.  13.  15.   1.   0.   0.   0.   9.\n",
      "   16.  16.   5.   0.   0.   0.   0.   3.  13.  16.  16.  11.   5.   0.\n",
      "    0.   0.   0.   3.  11.  16.   9.   0.]\n",
      " [  0.   0.   7.  15.  13.   1.   0.   0.   0.   8.  13.   6.  15.   4.\n",
      "    0.   0.   0.   2.   1.  13.  13.   0.   0.   0.   0.   0.   2.  15.\n",
      "   11.   1.   0.   0.   0.   0.   0.   1.  12.  12.   1.   0.   0.   0.\n",
      "    0.   0.   1.  10.   8.   0.   0.   0.   8.   4.   5.  14.   9.   0.\n",
      "    0.   0.   7.  13.  13.   9.   0.   0.]\n",
      " [  0.   0.   0.   1.  11.   0.   0.   0.   0.   0.   0.   7.   8.   0.\n",
      "    0.   0.   0.   0.   1.  13.   6.   2.   2.   0.   0.   0.   7.  15.\n",
      "    0.   9.   8.   0.   0.   5.  16.  10.   0.  16.   6.   0.   0.   4.\n",
      "   15.  16.  13.  16.   1.   0.   0.   0.   0.   3.  15.  10.   0.   0.\n",
      "    0.   0.   0.   2.  16.   4.   0.   0.]]\n",
      "\n",
      "First 5 labels: [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas\n",
    "\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "#print(digits)\n",
    "\n",
    "X,y = digits.data,digits.target\n",
    "print('X ~ n_samples x n_features:', X.shape)\n",
    "print('y ~ n_samples:', y.shape)\n",
    "\n",
    "print('\\nFirst 5 samples:\\n', X[:5, :])\n",
    "print('\\nFirst 5 labels:', y[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " After stratefication.................\n",
      "All: [  9.90539789  10.1279911    9.84974958  10.1836394   10.07234279\n",
      "  10.1279911   10.07234279   9.96104619   9.68280467  10.01669449]\n",
      "Training: [  9.87379362  10.09651076   9.87379362  10.17074981  10.09651076\n",
      "  10.09651076  10.09651076   9.94803267   9.72531552  10.02227171]\n",
      "Test: [ 10.          10.22222222   9.77777778  10.22222222  10.          10.22222222\n",
      "  10.          10.           9.55555556  10.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=1234,\n",
    "                                                    stratify=y)\n",
    "\n",
    "X_trainsub, X_valid, y_trainsub, y_valid = train_test_split(X_train, y_train,\n",
    "                                                            test_size=0.5,\n",
    "                                                            random_state=1234,\n",
    "                                                            stratify=y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\" After stratefication.................\")\n",
    "\n",
    "print('All:', np.bincount(y) / float(len(y)) * 100.0)\n",
    "print('Training:', np.bincount(y_train) / float(len(y_train)) * 100.0)\n",
    "print('Test:', np.bincount(y_test) / float(len(y_test)) * 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96444444444444444"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#prediction = classifier.predict(X_test)\n",
    "pred_y = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "#print(prediction)\n",
    "#print(y_test)\n",
    "\n",
    "classifier.score(X_test, y_test) #### CASE1: Simple regression : 0.96444444444444444\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96888888888888891"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#pipeline = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
    "#pipeline.fit(X_test, y_train)\n",
    "#pipeline.score(X_train, y_test)\n",
    "\n",
    "#vectorizer = TfidfVectorizer()\n",
    "#vectorizer.fit(text_train)\n",
    "\n",
    "#X_train = vectorizer.transform(text_train)\n",
    "#X_test = vectorizer.transform(text_test)\n",
    "\n",
    "#### vectorizor NOT working as expected\n",
    "\n",
    "\n",
    "clf = LogisticRegression()\n",
    "grid = GridSearchCV(clf, param_grid={'C': [.1, 1, 10, 100]}, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.score(X_test, y_test)  ## case 2: with pipeline: 0.96888888888888891\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples correctly classified:\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  72  73\n",
      "  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 115 116 117 118 120 121 122 123 124 125 126 127 128\n",
      " 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146\n",
      " 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164\n",
      " 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182\n",
      " 184 185 186 187 188 189 190 191 192 193 194 195 196 198 199 200 201 202\n",
      " 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220\n",
      " 221 222 223 224 225 226 227 228 229 230 232 233 234 235 236 237 238 239\n",
      " 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257\n",
      " 258 260 261 262 263 264 265 267 268 269 270 271 272 273 274 275 276 277\n",
      " 278 279 280 281 282 283 285 286 287 288 289 290 291 292 293 294 295 296\n",
      " 297 298 299 300 301 303 304 305 306 307 308 309 310 311 312 313 314 315\n",
      " 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333\n",
      " 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351\n",
      " 352 353 354 355 356 357 358 359 360 362 363 364 365 366 367 368 369 370\n",
      " 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388\n",
      " 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 406 407\n",
      " 408 409 410 411 412 413 414 416 417 418 419 420 421 422 423 424 425 426\n",
      " 427 428 429 430 431 432 433 434 435 436 437 440 441 442 443 444 445 446\n",
      " 448 449]\n",
      "\n",
      "Samples incorrectly classified:\n",
      "[ 41  71 119 183 197 231 259 266 284 302 361 405 415 438 439 447]\n"
     ]
    }
   ],
   "source": [
    "classifier.score(X_train, y_train)\n",
    "\n",
    "print('Samples correctly classified:')\n",
    "correct_idx = np.where(pred_y == y_test)[0]\n",
    "print(correct_idx)\n",
    "\n",
    "print('\\nSamples incorrectly classified:')\n",
    "incorrect_idx = np.where(pred_y != y_test)[0]\n",
    "print(incorrect_idx)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
